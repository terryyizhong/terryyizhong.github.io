
# üìù Publications 


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TSD 2025</div><img src='images/TSD-V1.2.drawio.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
[RECA-PD: A Robust Explainable Cross-Attention Method for Speech-based Parkinson's Disease Classification](https://arxiv.org/abs/2507.03594) \\
**Terry Yi Zhong**, Cristian Tejedor-Garcia,  Martha Larson, Bastiaan R. Bloem. [**[Code]**](https://github.com/terryyizhongru/RECA-PD) 

**Contribution**:
- A novel, robust, and explainable method for speech-based PD classification that delivers more clinically relevant explanations
- Results show that RECA-PD offer a better trade-off between explainability and performance
</div>
</div>


``INTERSPEECH 2025`` [Evaluating the Usefulness of Non-Diagnostic Speech Data for Developing Parkinson's Disease Classifiers](https://arxiv.org/abs/2505.18722)

**Terry Yi Zhong**, Esther Janse, Cristian Tejedor-Garcia, Louis ten Bosch, Martha Larson.


``ICASSP 2024 `` [SynthTab: Leveraging Synthesized Data for Guitar Tablature Transcription](https://ieeexplore.ieee.org/document/10447902)

Yongyi Zang*, **Yi Zhong\***, Frank Cwitkowitz, Zhiyao Duan. [**[Demo Page]**](https://synthtab.dev//)


``INTERSPEECH 2024`` [GTR-Voice: Articulatory Phonetics Informed Controllable Expressive Speech Synthesis](https://www.isca-archive.org/interspeech_2024/li24pa_interspeech.html)

Zehua Kcriss Li, Meiying Melissa Chen, **Yi Zhong**, Pinxin Liu, Zhiyao Duan. [**[Demo Page]**](https://demo.gtr-voice.com//)


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">INTERSPEECH 2023</div><img src='images/EETTS.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
[EE-TTS: Emphatic Expressive TTS with Linguistic Information](https://www.isca-archive.org/interspeech_2023/zhong23_interspeech.html) \\
**Yi Zhong**, <font size=2>Chen Zhang, Xule Liu, Chenxi Sun, Weishan Deng, Haifeng Hu, Zhongqian Sun.</font> [**[Demo Page]**](https://expressive-emphatic-ttsdemo.github.io/) 

**Contribution**:
- EE-TTS can identify appropriate emphasis positions from text and synthesize expressive speech with emphasis and linguistic information.
- This work outperforms baseline with expressiveness-MOS improvements from 3.76 to 4.25 and naturalness-MOS from 3.67 to 4.34.
- EE-TTS helps build AI playmate services for the world's most-played mobile MOBA game [Honor of Kings](https://www.honorofkings.com/global-en/) (DAU 100+ million).

</div>
</div>